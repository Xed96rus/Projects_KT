# -*- coding: utf-8 -*-
"""Создание простого искусственного нейрона

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13MhdWnjhggDvqfoO9ZZTkRmpXZIosw_k
"""

# Модуль Neuron
import numpy as np

"""# Класс, представляющий искусственный нейрон"""

# Создание класса "Нейрон"
class Neuron:
  # Инициализатор объекта, нужен всегда
  def __init__(self, w, activation_func):
    self.w = w
    self.activation_func = activation_func
  # Функция, реализующая блшок нелинейного преобразования
  def y (self, x):
    return self.activation_func(np.dot(self.w, x))

def act_func(s):
  return s
print(act_func(3))

"""## Работа с объектами класса `Neuron`"""

n = Neuron(w = np.array([1, 1, 1]),
           activation_func = act_func)
print(n.y(np.array([0, 1, 0])))

"""### Работа с анонимными функциями"""

act_func_lambda = lambda s: np.power(s, 2)
print(act_func_lambda(3))

"""Удобство в том, что анонимная функиця (или лямбда-выражение) даёт возможность создать её сразу в выражении (определить, создать на месте)"""

n_lambda = Neuron(w = np.array([1, 1, 1]),
           activation_func = lambda s: np.sqrt(s))
print(n_lambda.y(np.array([0, 0, 4])))

# Создание класса "Нейрон"
class Neuron2:
  def __init__(self, w,
               activation_func = lambda s: s):
    self.w = w
    self.activation_func = activation_func

  def y (self, x):
    try: # попытайся выполнить
      return self.activation_func(np.dot(self.w, np.array(x)))
    except: # если ошибка то сделай это
      print('Размерности векторов "_w" и "x" не совпадают')

n_default = Neuron2(w = np.array([1, 1, 1]))
print(n_default.y(x = np.array([1, 1])))

n_fish = Neuron2(w = [5, 4, 1, 1])
print(n_fish.y(x = [1, 1, 0, 0]))

"""Мы взяли и сравнили, идти ли на рыбалку, но что делать дальше с числом, как принять решение "идти" или "не идти"?"""

n_fish = Neuron2(w = [5, 4, 1, 1], activation_func = lambda s: 1 / (1 + np.exp(-s)))
print(n_fish.y(x = [1, 1, 0, 0]))

# Создание класса "Нейрон"
class Neuron3:
  def __init__(self, w, # начальное значение вектора весов
               b,       # Порог активации нейрона
               activation_func = lambda s: s):
    self.w = w
    self.b = b
    self.activation_func = activation_func

  def y (self, x):
    try:
      return self.activation_func(np.dot(self.w, np.array(x)))
    except Exception as e:
      print(e) # Найди е и напиши что оно значит
      return None
  # Функция активации нейрона
  def activate(self, x):
    return 1 if self.y(x) >= self.b else 0

"""Добавляем сигмоид в функцию"""

n_fish = Neuron3(w = [5, 4, 1, 1],
                 b = 0.5,
                 activation_func = lambda s: 1 / (1 + np.exp(-s))) # сигмоида
print(n_fish.y([1, 2, 3, 0]))
print(n_fish.activate(x = [0, 1, 0, 0]))

n_fish = Neuron3(w = [5, 4, 1, 1],
                 b = 0.5,
                 activation_func = lambda s: np.tanh(s)) # Тангенс гиперболический
print(n_fish.activate(x = [0, 1, 0, 0]))

"""# Персептроны

## Простейший однослойный персептрон
"""

simple_one_layer_perceptron = Neuron3(w = [1] * 15,
                           b = 7,
                           activation_func = lambda s: s)
print(simple_one_layer_perceptron.activate(x = [int(i) for i in '010111010010010']))

class SimplestOneLayerPerceptron(Neuron3):
  def __init__(self, w, b):
    super().__init__(w = w, b = b)

  def fit(self, num_of_lessons, train_set, topic_object):
      # Цикл обучения
    for lesson in range(num_of_lessons):
      lesson_object = train_set[np.random.randint(0, len(train_set))] # Берём случайный элемент из датасета для обучения
      lesson_predict = bool(self.activate(x = lesson_object))         # Результат распознования
      #print(f'Объект: {lesson_object}, результат распознания: {lesson_predict}')
      # Первое правило Хебба
      if (lesson_object == topic_object) and (lesson_predict == False):
        print('Правило 1')
        for w in self.w:
          w += 1
      # Второе правило Хебба
      elif (lesson_object != topic_object) and (lesson_predict == True):
        print('Правило 2')
        for w in self.w:
          w -= 1
    for w in self.w:
      print(w)

num0 = list('111101101101111')
num1 = list('001001001001001')
num2 = list('111001111100111')
num3 = list('111001111001111')
num4 = list('101101111001001')
num5 = list('111100111001111')
num6 = list('111100111101111')
num7 = list('111001001001001')
num8 = list('111101111101111')
num9 = list('111101111001111')
nums = [num0, num1, num2, num3, num4, num5, num6, num7, num8, num9]
print([int(i) for i in list('101010')])
def str_list_to_int_list(str_list):
  return [int(el) for el in str_list]

print(str_list_to_int_list(num1))

"""Дописали, как перевести строку в int список


"""

solp = SimplestOneLayerPerceptron(w = [0] * 15, b = 7)
bool(solp.activate(x = str_list_to_int_list(num1)))

solp.fit(num_of_lessons = 100,
         train_set = [str_list_to_int_list(num) for num in nums],
         topic_object = str_list_to_int_list(num0))