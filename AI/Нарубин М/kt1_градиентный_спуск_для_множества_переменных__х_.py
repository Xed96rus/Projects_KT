# -*- coding: utf-8 -*-
"""KT1 Градиентный спуск для множества переменных "Х"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aDJHJgAokf3Lc4tAwu687kx0Jei0UmEW

# Линейная аппроксимация МГС

Подключим необходимые далее модули Python:
"""

import numpy as np
import matplotlib.pyplot as plt

"""##Градиент предоставленный"""

def mean_squared_error(y_true, y_predicted):
  return np.sum((y_true - y_predicted)**2) / len(y_true)
def gradient_descent(x, y,
                     n_iter = 1000, l_rate = 0.0001, stop_threshold = 1e-8,
                     print_iters = True, visualize = True):
  # Инициализировать вес, отклонение и прочие входящие параметры:
  current_weight = 0.1
  current_bias = 0.01
  # n_iter = n_iter
  # l_rate = l_rate
  n = float(len(x))

  # Зададим параметры метода:
  costs = []
  weights = []
  previous_cost = None

  # Оценка оптимальных параметров.
  # Двигаясь в цикле от итерации к итерации, ...
  for i in range(n_iter):
    # ... вычисляем предсказываемое значение:
    y_predicted = (current_weight * x) + current_bias
    # ... вычисляем текущую погрешность:
    current_cost = mean_squared_error(y, y_predicted)

    # Оценка погрешности: если достигли требуемой точности,
    # то завершаем выполнение нашего метода:
    if previous_cost and np.abs(previous_cost - current_cost) <= stop_threshold:
      break

    # Если необходимо продолжить, фиксируем потерю на нынешней итерации:
    previous_cost = current_cost

    costs.append(current_cost)
    weights.append(current_weight)

    # Вычисляем градиенты:
    weight_derivative = -(2/n) * sum(x * (y - y_predicted))
    bias_derivative = -(2/n) * sum(y - y_predicted)

    # Обновить веса и отклонения:
    current_weight = current_weight - (l_rate * weight_derivative)
    current_bias = current_bias - (l_rate * bias_derivative)

    # Отобразим параметры итерации, если хочется:
    if print_iters:
      print(f"Итерация {i+1}: Стоимость {current_cost}, \
      Вес: {current_weight}, Отклонение: {current_bias}")

  #Визуализация, если нужно:
  if visualize:
    plt.figure(figsize = (10, 8))
    plt.plot(weights, costs)
    plt.scatter(weights, costs, marker = 'o', color = 'red')
    plt.title("Погрешность / Вес")
    plt.xlabel("Вес")
    plt.ylabel("Погрешность")
    plt.show()

  return (current_weight, current_bias)

"""## Градиент мой"""

def MSE(y_true, y_pred):
  return np.mean(((y_true - y_pred)**2) / len(y_true))
def MULTY(xs, ys, dim):
  try:
    return sum(np.array([x[dim] for x in xs]) * ys)
  except:
    return sum(np.array(xs * ys))

x = [10, 4, 10]
print(sum(np.array([x[i] for i in range(3)]) / 3))

def example(xs, ys, dim):
  return sum(np.array([x[dim] for x in xs]) * ys)
print(example(xs = [[1, 2], [3, 4]], ys = np.array([10, 20]), dim = 0))
print(MULTY(xs = [[1, 2], [3, 4]], ys = np.array([10, 20]), dim = 0))

def GRADIENT(xs, ys, iters = 1000, learning_speed = 0.0001, stop_EPS = 0.000000001, print_iters = True):
  xs = np.array(xs)
  ys = np.array(ys)
  try:
    w_1 = [0.01] * len(xs[0])
    w_0 = 0.1
  except:
    w_1 = [0.01]
    w_0 = 0.1
  N = float(len(xs)) # количество объектов
  losses = [] # Наши "E"
  w_1_history = []
  previos_E = None

  for i in range(iters):
    # Предсказание для всех объектов
    ys_predict = np.dot(xs, w_1) + w_0

    # Ошибка (MSE)
    E = MSE(ys, ys_predict)

    # Проверка на остановку
    if previos_E and abs((previos_E - E)) <= stop_EPS:
        break
    previos_E = E
    losses.append(E)
    w_1_history.append(w_1.copy())

    # Градиенты
    grad_w_1 = -(2/N) * np.dot(xs.T, (ys - ys_predict))  # Градиент для весов
    grad_w_0 = -(2/N) * sum(ys - ys_predict)  # Градиент для смещения

    # Обновление весов и смещения
    w_1 = w_1 - learning_speed * grad_w_1
    w_0 = w_0 - learning_speed * grad_w_0


    if print_iters:
      print(f"Итерация {i+1}: Стоимость {E}, \
      Вес: {w_1}, Отклонение: {w_0}")
  if print_iters:
    try:
        plt.figure(figsize=(15, 5))
        for dim in range(xs.shape[1]):
            plt.subplot(1, xs.shape[1], dim + 1)
            plt.plot([w[dim] for w in w_1_history], losses)
            plt.scatter([w[dim] for w in w_1_history], losses, marker='o', color='red')
            plt.title(f"Погрешность / Вес {dim + 1}")
            plt.xlabel(f"Вес {dim + 1}")
            plt.ylabel("Погрешность")
    except:
      plt.figure(figsize=(10, 8))
      plt.plot(w_1_history, losses)
      plt.scatter(w_1_history, losses, marker='o', color='red')
      plt.title("Погрешность / Итерации")
      plt.xlabel("Итерации")
      plt.ylabel("Погрешность")
      plt.show()
      plt.show()
  return w_1, w_0

"""Зададим массив данных:

# Моя база данных для тестирования
"""

crime_data_by_height = {
    158: [
        {'foot_size': 22, 'gender': 'F', 'hair_length': 35}
    ],
    160: [
        {'foot_size': 24, 'gender': 'F', 'hair_length': 32}
    ],
    162: [
        {'foot_size': 23, 'gender': 'F', 'hair_length': 30}
    ],
    165: [
        {'foot_size': 23, 'gender': 'F', 'hair_length': 28}
    ],
    168: [
        {'foot_size': 24, 'gender': 'F', 'hair_length': 25}
    ],
    175: [
        {'foot_size': 25, 'gender': 'M', 'hair_length': 2}
    ],
    178: [
        {'foot_size': 25, 'gender': 'M', 'hair_length': 6}
    ],
    180: [
        {'foot_size': 26, 'gender': 'M', 'hair_length': 3}
    ],
    183: [
        {'foot_size': 27, 'gender': 'M', 'hair_length': 5}
    ],
    188: [
        {'foot_size': 28, 'gender': 'M', 'hair_length': 4}
    ]
}

"""#Сравнение работы для 1 признака (X)"""

def prepare_data_for_DB(data):
    """Преобразует данные для использования в градиентном спуске."""
    X_data = []
    Y_data = []

    for height, features in data.items():
        for feature in features:
            #X_data.append([feature['foot_size'],0 if feature['gender'] == 'M' else 1,  # M -> 0, F -> 1feature['hair_length']])
            X_data.append(feature['foot_size'])
            Y_data.append(height)
            return np.array(X_data), np.array(Y_data)

"""## Работа градиентного спуска с пары"""

X, Y = prepare_data_for_DB(crime_data_by_height)
res = gradient_descent(X, Y, 1000, 0.0001, 1e-5, True)
print(f"Прямая имеет вид: y = {res[0]} * x + {res[1]}")

"""## Работа моего градиентного спуска"""

xs, ys = np.array(prepare_data_for_DB(crime_data_by_height))
print(xs)
res = GRADIENT(xs, ys, 1000, 0.0001, 1e-5, True)
print(f" \n Прямая имеет вид: y = {res[0]} * x + {res[1]}")

"""# Работа с несколькими признаками (X)"""

def prepare_data_for_tests(data):
    """Преобразует данные для использования в градиентном спуске."""
    X_data = []
    Y_data = []

    for height, features in data.items():
        for feature in features:
            X_data.append([feature['foot_size'],
                           0 if feature['gender'] == 'M' else 1,  # M -> 0, F -> 1
                           feature['hair_length']])
            Y_data.append(height)
            return np.array(X_data), np.array(Y_data)

X_test, Y_test = (prepare_data_for_tests(crime_data_by_height))

res = GRADIENT(X_test, Y_test, 1000, 0.0001, 1e-5, True)
print(f" \n Прямая имеет вид: y = {res[0]} * x + {res[1]}")

"""# Автоматическое дифферинцирование"""

class DualNumber:
  # a + b*eps
  def __init__(self, a, b):         # Говорим, с какими переменными мы работаем и что они локальные
    self.a = a
    self.b = b
  def __add__(self, other):         # По правилу арифметики с дуальными числами, чтобы мы могли их складывать
    if isinstance(other, DualNumber):
      return DualNumber(self.a + other.a, self.b + other.b)
    else:
      return DualNumber(self.a + other, self.b)
  def __radd__(self, other):
    return self + other
  def __sub__(self, other):
    if isinstance(other, DualNumber):
      return DualNumber(self.a - other.a, self.b - other.b)
    else:
      return DualNumber(self.a - other, self.b)
  def __rsub__(self, other):         # По правилу арифметики с дуальными числами, чтобы мы могли их складывать
    if isinstance(other, DualNumber):
      return DualNumber(other.a - self.a, other.b - self.b)
    else:
      return DualNumber(other - self.a, self.b)
  def __mul__(self, other):         # По правилу арифметики с дуальными числами, чтобы мы могли их умножать
    if isinstance(other, DualNumber):
      return DualNumber(self.a * other.a, self.b * other.a + self.a * other.b)
    else:
      return DualNumber(self.a * other, self.b * other)
  def __rmul__(self, other):         # По правилу арифметики с дуальными числами, чтобы мы могли их умножать
    return self * other
  def __truediv__(self, other):
        if isinstance(other, DualNumber):
            return DualNumber(self.a / other.a, (self.b * other.a - self.a * other.b) / (other.a ** 2))
        else:
            return DualNumber(self.a / other, self.b / other)
  def __rtruediv__(self, other):
      return DualNumber(other, 0).__truediv__(self)
  def __pow__(self, other):
    return DualNumber(self.a**other, self.b * other * self.a **(other - 1))
  def __repr__(self):
        return f"({self.a} + {self.b}ε)"

"""## Проверка сложения"""

z = DualNumber(1, 1) # 1 + 1 * eps
v = DualNumber(4, 2) # 4 + 2 * eps
res = z + v
print(f"Число а = {res.a}, число b = {res.b} \nres = {res.a} + {res.b}*eps")
res = z + 4
print(f"Число а = {res.a}, число b = {res.b} \nres = {res.a} + {res.b}*eps")
res = 4 + z
print(f"Число а = {res.a}, число b = {res.b} \nres = {res.a} + {res.b}*eps")

"""## Проверка вычитания"""

z = DualNumber(1, 1) # 1 + 1 * eps
v = DualNumber(4, 2) # 4 + 2 * eps
res = z - v
print(f"Число а = {res.a}, число b = {res.b} \nres = {res.a} + {res.b}*eps")
res = z - 4
print(f"Число а = {res.a}, число b = {res.b} \nres = {res.a} + {res.b}*eps")
res = 4 - z
print(f"Число а = {res.a}, число b = {res.b} \nres = {res.a} + {res.b}*eps")

"""## Проверка умножения"""

z = DualNumber(1, 1) # 1 + 1 * eps
v = DualNumber(4, 2) # 4 + 2 * eps
res2 = z * v
print((f"Число а = {res2.a}, число b = {res2.b} \nres2 = {res2.a} + {res2.b}*eps"))

res2 = z * 3
print((f"Число а = {res2.a}, число b = {res2.b} \nres2 = {res2.a} + {res2.b}*eps"))
res2 = 3 * z
print((f"Число а = {res2.a}, число b = {res2.b} \nres2 = {res2.a} + {res2.b}*eps"))

"""## Проверка возведения в степень"""

z = DualNumber(1, 1) # 1 + 1 * eps
v = DualNumber(4, 2) # 4 + 2 * eps
res3 = v ** 2
print(f"Число а = {res3.a}, число b = {res3.b} \nres = {res3.a} + {res3.b}*eps")

"""## Работа с конкретными функциями (часные производные функции двух переменных)

$\partial$
"""

f = lambda x, y: x * (x + y) + y * y
eps = DualNumber(0, 1)

x0 = 2
y0 = 3

print(f"∂f/∂x = {f(x0 + eps, y0).b}")
print(f"∂f/∂y = {f(x0, y0 + eps).b}")

g = lambda w0, w1, w2: (w0 + w1 * 0.3 + w2 * 0.9)**3
ws = [2, 5, 10]
print(f"∂f/∂w0 = {g(ws[0] + eps, ws[1], ws[2]).b}")
print(f"∂f/∂w1 = {g(ws[0], ws[1] + eps, ws[2]).b}")
print(f"∂f/∂w2 = {g(ws[0], ws[1], ws[2] + eps).b}")

"""# Градиентный спуск с автоматическим дифференцированием

Наше исходное уравнение:
$$
\frac{\partial}{\partial w_j} \left[ \frac{1}{N} \sum_{i=1}^{N} (y_i - y^*_i)^2 \right] $$
"""

def MSE(y_true, y_pred):
  return np.sum(((y_true - y_pred)**2) / len(y_true))
def MULTY(xs, ys, dim):
  try:
    return sum(np.array([x[dim] for x in xs]) * ys)
  except:
    return sum(np.array(xs * ys))

def linear_apr(xs, w_1, w_0):
  return np.array([np.sum(w_1 * x) + w_0 for x in xs])

def GRADIENT_WITH_DIFF(xs, ys, ys_predicted_fun = linear_apr, loss_fun = MSE, iters = 1000, learning_speed = 0.0001, stop_EPS = 0.000000001, print_iters = True):
  xs = np.array(xs)
  ys = np.array(ys)
  N = float(len(xs)) # количество объектов
  losses = [] # Наши "E"
  w_1_history = []
  previos_E = None
  if xs.ndim == 1:
      xs = xs.reshape(-1, 1)  # Преобразуем в (n, 1)
  n = xs.shape[1]
  w_1 = np.array([0.01 for _ in range(n)])
  w_0 = 0.1


  for i in range(iters):
    # Предсказание для всех объектов
    ys_predict = ys_predicted_fun(xs, DualNumber(w_1, 1), w_0)

    # Ошибка (MSE)
    E = loss_fun(ys, ys_predict)
    #E = E * DualNumber(1, 1)
    # Проверка на остановку
    if previos_E and abs((previos_E.a - E.a)) <= stop_EPS:
        break
    previos_E = E
    losses.append(E.a)
    w_1_history.append(w_1)

    # Дифференциальное уравнение
    grad_w_1 = E.b
    grad_w_0 = 1

    # Обновление весов и смещения
    w_1 = w_1 + (learning_speed * grad_w_1)
    w_0 = w_0 + (learning_speed * grad_w_0)


    if print_iters:
      print(f"Итерация {i+1}: Стоимость {E}, \
      Вес: {w_1}, Отклонение: {w_0}")
  if print_iters:
    try:
        plt.figure(figsize=(15, 5))
        for dim in range(xs.shape[1]):
            plt.subplot(1, xs.shape[1], dim + 1)
            plt.plot([w[dim].a for w in w_1_history], losses)
            plt.scatter([w[dim].a for w in w_1_history], losses, marker='o', color='red')
            plt.title(f"Погрешность / Вес {dim + 1}")
            plt.xlabel(f"Вес {dim + 1}")
            plt.ylabel("Погрешность")
    except:
      plt.figure(figsize=(10, 8))
      plt.plot(w_1_history, losses)
      plt.scatter(w_1_history, losses, marker='o', color='red')
      plt.title("Погрешность / Итерации")
      plt.xlabel("Итерации")
      plt.ylabel("Погрешность")
      plt.show()
      plt.show()
  return w_1, w_0

xs, ys = np.array(prepare_data_for_DB(crime_data_by_height))
print(xs)
res = GRADIENT_WITH_DIFF(xs, ys)
print(f" \n Прямая имеет вид: y = {res[0]} * x + {res[1]}")

"""Прямая имеет вид: y = [7.16220139] * x + 0.42510006309622017

## DeepSeek
"""

import numpy as np
import matplotlib.pyplot as plt

class DualNumber:
    def __init__(self, a, b):
        self.a = a
        self.b = b

    def __add__(self, other):
        if isinstance(other, DualNumber):
            return DualNumber(self.a + other.a, self.b + other.b)
        else:
            return DualNumber(self.a + other, self.b)

    def __radd__(self, other):
        return self + other

    def __sub__(self, other):
        if isinstance(other, DualNumber):
            return DualNumber(self.a - other.a, self.b - other.b)
        else:
            return DualNumber(self.a - other, self.b)

    def __rsub__(self, other):
        if isinstance(other, DualNumber):
            return DualNumber(other.a - self.a, other.b - self.b)
        else:
            return DualNumber(other - self.a, self.b)

    def __mul__(self, other):
        if isinstance(other, DualNumber):
            return DualNumber(self.a * other.a, self.b * other.a + self.a * other.b)
        else:
            return DualNumber(self.a * other, self.b * other)

    def __rmul__(self, other):
        return self * other

    def __truediv__(self, other):
        if isinstance(other, DualNumber):
            return DualNumber(self.a / other.a, (self.b * other.a - self.a * other.b) / (other.a ** 2))
        else:
            return DualNumber(self.a / other, self.b / other)

    def __rtruediv__(self, other):
        return DualNumber(other, 0).__truediv__(self)

    def __pow__(self, other):
        return DualNumber(self.a**other, self.b * other * self.a **(other - 1))

    def __repr__(self):
        return f"({self.a} + {self.b}ε)"

def linear_apr(xs, w_1, w_0):
    return np.array([w_1 * x + w_0 for x in xs])

def MSE(y_true, y_pred):
    """
    Вычисляет среднеквадратичную ошибку (MSE) с поддержкой DualNumber.
    """
    diff = y_true - y_pred
    squared_diff = diff ** 2
    mse = np.sum(squared_diff) / len(y_true)
    return mse

def prepare_data_for_DB(data):
    X_data = []
    Y_data = []

    for height, features in data.items():
        for feature in features:
            X_data.append(feature['foot_size'])
            Y_data.append(height)

    return np.array(X_data), np.array(Y_data)

def GRADIENT_WITH_DIFF(xs, ys, iters=1000, learning_speed=0.0001, stop_EPS=0.000000001, print_iters=True):
    xs = np.array(xs)
    ys = np.array(ys)
    N = float(len(xs))
    losses = []
    w_1_history = []
    previos_E = None

    # Инициализация весов как DualNumber
    w_1 = DualNumber(0.01, 1)  # w_1 имеет начальное значение 0.01 и производную 1
    w_0 = DualNumber(0.1, 1)   # w_0 имеет начальное значение 0.1 и производную 1

    for i in range(iters):
        # Предсказание с использованием DualNumber
        ys_predict = linear_apr(xs, w_1, w_0)

        # Ошибка (MSE) с использованием DualNumber
        E = MSE(ys, ys_predict)

        # Проверка на остановку
        if previos_E and abs((previos_E.a - E.a)) <= stop_EPS:
            break
        previos_E = E
        losses.append(E.a)
        w_1_history.append(w_1.a)

        # Вычисление градиентов через производные DualNumber
        grad_w_1 = E.b  # Производная по w_1
        grad_w_0 = E.b  # Производная по w_0

        # Обновление весов (используем только .a, так как градиенты уже числа)
        w_1 = DualNumber(w_1.a - learning_speed * grad_w_1, 1)
        w_0 = DualNumber(w_0.a - learning_speed * grad_w_0, 1)

        if print_iters:
            print(f"Итерация {i+1}: Стоимость {E.a}, Вес: {w_1.a}, Отклонение: {w_0.a}")

    if print_iters:
        plt.figure(figsize=(10, 8))
        plt.plot(w_1_history, losses)
        plt.scatter(w_1_history, losses, marker='o', color='red')
        plt.title("Погрешность / Итерации")
        plt.xlabel("Итерации")
        plt.ylabel("Погрешность")
        plt.show()

    return w_1.a, w_0.a

# Подготовка данных
crime_data_by_height = {
    158: [{'foot_size': 22, 'gender': 'F', 'hair_length': 35}],
    160: [{'foot_size': 24, 'gender': 'F', 'hair_length': 32}],
    162: [{'foot_size': 23, 'gender': 'F', 'hair_length': 30}],
    165: [{'foot_size': 23, 'gender': 'F', 'hair_length': 28}],
    168: [{'foot_size': 24, 'gender': 'F', 'hair_length': 25}],
    175: [{'foot_size': 25, 'gender': 'M', 'hair_length': 2}],
    178: [{'foot_size': 25, 'gender': 'M', 'hair_length': 6}],
    180: [{'foot_size': 26, 'gender': 'M', 'hair_length': 3}],
    183: [{'foot_size': 27, 'gender': 'M', 'hair_length': 5}],
    188: [{'foot_size': 28, 'gender': 'M', 'hair_length': 4}]
}

xs, ys = prepare_data_for_DB(crime_data_by_height)
print("Данные:", xs, ys)

# Автоматическое дифференцирование
print("\nАвтоматическое дифференцирование:")
w_1_diff, w_0_diff = GRADIENT_WITH_DIFF(xs, ys, iters=1000, learning_speed=0.0001, stop_EPS=1e-5, print_iters=True)
print(f"Результат автоматического дифференцирования: y = {w_1_diff} * x + {w_0_diff}")