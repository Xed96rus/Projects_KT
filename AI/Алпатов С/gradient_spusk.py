# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oiPM_IEHbZq0caVmiUfbPkeipyA3d6aY

Библиотеки python
"""

import numpy as np
import matplotlib.pyplot as plt

"""# Новый раздел"""

def MSE(ys_true, ys_pred):
    return np.mean((ys_true - ys_pred) ** 2) / len(ys_true)

# Инициализация весов и смещений

def GRADIENT(xs, ys, iters=1000, learning_speed=0.0001, stop_EPS=1e-2, print_iters=True):

    # Преобразуем входные данные в numpy массивы для векторных операций
    xs = np.array(xs)
    ys = np.array(ys)

    # Если данные одномерные, преобразуем в столбец (N, 1)
    if xs.ndim == 1:
        xs = xs.reshape(-1, 1)
    n = xs.shape[1]
    N = len(xs)

    # Инициализация параметров модели
    # Инициализируем веса w_1 нулями (размерность соответствует количеству признаков в xs)
    w_1 = np.zeros(xs.shape[1])
    w_0 = 0.01  # Смещение (bias)

    N = float(len(xs))  # число объектов в выборке
    losses = []  # Это "E" история значений ошибки (используется для графика)
    weights_history = []  # История весов
    bias_history = []  # История смещений
    previos_E = None #  хранит ошибку на предыдущем шаге для проверки критерия остановки

    for i in range(iters):
        # Предсказание для всех объектов. Формула: y = w*x + b (в векторной форме)
        ys_predict = np.dot(xs, w_1) + w_0

        # Вычисляем текущую ошибку модели (MSE)
        E = MSE(ys, ys_predict)
        #print("MSE(xs, ys, 0):", MSE(ys, ys_predict))  #
        #print("MSE(xs, ys, 1):", MSE(ys, ys_predict))  #

        # Проверка на остановку. Если разница между предыдущим и текущим значением MSE меньше порога stop_EPS, значит, градиентный спуск сошелся, то выходим из цикла
        if previos_E and abs((previos_E - E)) <= stop_EPS:
            if print_iters:
                print(f"Ранняя остановка на итерации {i+1}")
            break
        # Сохраняем историю значений ошибки, весов и смещений. append() - добавляет элемент в () в конец списка
        previos_E = E
        losses.append(E)
        weights_history.append(w_1.copy())
        bias_history.append(w_0)

        # Градиенты
        grad_w_1 = -(2/N) * np.dot(xs.T, (ys - ys_predict))  # Градиент для весов
        grad_w_0 = -(2/N) * sum(ys - ys_predict)  # Градиент для смещения

        # Обновление весов и смещения
        w_1 = w_1 - learning_speed * grad_w_1
        w_0 = w_0 - learning_speed * grad_w_0

        # Вывод информации о процессе обучения
        if print_iters and i % 100 == 0:
            print(f"Итерация {i+1}: Стоимость {E}, Вес: {w_1}, Отклонение: {w_0}")

    # Визуализация кривой обучения
    if print_iters:
        plt.figure(figsize=(10, 8))
        plt.plot(range(len(losses)), losses)
        plt.scatter(range(len(losses)), losses, marker='o', color='red')
        plt.title("Погрешность / Итерации")
        plt.xlabel("Итерации")
        plt.ylabel("Погрешность")
        plt.show()

    return w_1, w_0

# Пример данных
xs = [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]]
ys = [3, 5, 7, 9, 11, 13]

# Запуск градиентного спуска
w_1, w_0 = GRADIENT(xs, ys, iters=100, learning_speed=0.001, stop_EPS=1e-3, print_iters=True)

print(f"Итоговые веса: {w_1}, Итоговое смещение: {w_0}")

xs = [[22, 1, 2], [23, 3, 4], [24, 5, 6]]
ys = [150, 155, 160]


w_1, w_0 = GRADIENT(xs, ys, iters=1000, learning_speed=0.001, stop_EPS=1e-3, print_iters=True)
print(f"Итоговые веса: {w_1}, Итоговое смещение: {w_0}")